{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5a056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8f7da",
   "metadata": {},
   "source": [
    "# 1、数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b4847c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据个数： 30\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "class ISBI_Loader(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        # 初始化函数，读取所有data_path下的图片\n",
    "        self.data_path = data_path\n",
    "        self.imgs_path = glob.glob(os.path.join(data_path, 'image/*.png'))\n",
    "        #print(self.imgs_path)\n",
    " #返回所有匹配的文件路径列表（list），os将它们按照'/'或反斜杠拼接，glob是将寻找目录下所有的png文件\n",
    " \n",
    "    def augment(self, image, flipCode):\n",
    "        # 使用cv2.flip进行数据增强，filpCode为1水平翻转，0垂直翻转，-1水平+垂直翻转\n",
    "        #增加样本量\n",
    "        flip = cv2.flip(image, flipCode)\n",
    "        return flip\n",
    " \n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        # 根据index读取图片\n",
    "        image_path = self.imgs_path[index]\n",
    "        # 根据image_path生成label_path\n",
    "        label_path = image_path.replace('image', 'label')\n",
    "        # 读取训练图片和标签图片\n",
    "        image = cv2.imread(image_path)\n",
    "        label = cv2.imread(label_path)\n",
    "        # 将数据转为单通道的图片——灰度图\n",
    "        #------cv2.COLOR_BGR2RGB 将BGR格式转换成RGB格式，cv2.COLOR_BGR2GRAY 将BGR格式转换成灰度图片\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "       # print(image.shape)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        label = label.reshape(1, label.shape[0], label.shape[1])\n",
    "        # 处理标签，将像素值为255的改为1\n",
    "        if label.max() > 1:\n",
    "            label = label / 255\n",
    "        # 随机进行数据增强，为2时不做处理\n",
    "        flipCode = random.choice([-1, 0, 1, 2])\n",
    "        if flipCode != 2:\n",
    "            image = self.augment(image, flipCode)\n",
    "            label = self.augment(label, flipCode)  \n",
    "        return image, label\n",
    " \n",
    " \n",
    "    def __len__(self):\n",
    "        # 返回训练集大小\n",
    "        return len(self.imgs_path)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    isbi_dataset = ISBI_Loader(r\"E:\\opencv\\data\\train\")\n",
    "    print(\"数据个数：\", len(isbi_dataset))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=2, \n",
    "                                               shuffle=True)\n",
    "    for image, label in train_loader:\n",
    "        print(image.shape)\n",
    "        #batchsize、channel，长，宽"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2993df4f",
   "metadata": {},
   "source": [
    "# 二、网络建构\n",
    "## 1.写一个单独的二次卷积模块（因为unet模型每一次下采样/上采样的过程都需要卷积）\n",
    "## 2.下采样构建过程\n",
    "## 3.上采样过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdef6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module): #二次卷积的模块\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),  #进行两次卷积，卷积核3x3，填充1\n",
    "            nn.BatchNorm2d(out_channels),  #BN层---归一化，收敛更快\n",
    "            nn.ReLU(inplace=True),   #relu层,True表示覆盖原值\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    " \n",
    " \n",
    "class Down(nn.Module):  #\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    " \n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    " \n",
    " \n",
    "class Up(nn.Module):  #上采样\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    " \n",
    " \n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    " \n",
    " \n",
    "    def forward(self, x1, x2):   #前向传播\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    " \n",
    " \n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    " \n",
    " \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    " \n",
    " \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2a78e",
   "metadata": {},
   "source": [
    "# 输出unet网格结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc58eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (inc): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down1): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    " \n",
    " \n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    " \n",
    " \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    net = UNet(n_channels=3, n_classes=1)\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a2bd07",
   "metadata": {},
   "source": [
    "# 三、训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc7cd2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.5826978087425232\n",
      "Loss/train 0.5338716506958008\n",
      "Loss/train 0.4834027588367462\n",
      "Loss/train 0.450377881526947\n",
      "Loss/train 0.43487128615379333\n",
      "Loss/train 0.39949724078178406\n",
      "Loss/train 0.38635653257369995\n",
      "Loss/train 0.37084460258483887\n",
      "Loss/train 0.3496425747871399\n",
      "Loss/train 0.36434075236320496\n",
      "Loss/train 0.381354421377182\n",
      "Loss/train 0.3406447768211365\n",
      "Loss/train 0.3339272141456604\n",
      "Loss/train 0.34353503584861755\n",
      "Loss/train 0.33691439032554626\n",
      "Loss/train 0.32634496688842773\n",
      "Loss/train 0.33151936531066895\n",
      "Loss/train 0.3221985399723053\n",
      "Loss/train 0.3409501612186432\n",
      "Loss/train 0.31779399514198303\n",
      "Loss/train 0.33878180384635925\n",
      "Loss/train 0.3107496500015259\n",
      "Loss/train 0.3206009864807129\n",
      "Loss/train 0.323714017868042\n",
      "Loss/train 0.33790215849876404\n",
      "Loss/train 0.32091182470321655\n",
      "Loss/train 0.28774768114089966\n",
      "Loss/train 0.3045581579208374\n",
      "Loss/train 0.2861199378967285\n",
      "Loss/train 0.31806644797325134\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    " \n",
    "def train_net(net, device, data_path, epochs=1, batch_size=1, lr=0.00001):\n",
    "    # 加载训练集\n",
    "    isbi_dataset = ISBI_Loader(data_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=batch_size, \n",
    "                                               shuffle=True)\n",
    "    # 定义RMSprop算法\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    # 定义Loss算法\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # best_loss统计，初始化为正无穷\n",
    "    best_loss = float('inf')\n",
    "    # 训练epochs次\n",
    "    for epoch in range(epochs):\n",
    "        # 训练模式\n",
    "        net.train()\n",
    "        # 按照batch_size开始训练\n",
    "        for image, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 将数据拷贝到device中\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred = net(image)\n",
    "            # 计算loss\n",
    "            loss = criterion(pred, label)\n",
    "            print('Loss/train', loss.item())\n",
    "            # 保存loss值最小的网络参数\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), 'best_model.pth')\n",
    "            # 更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    # 选择设备，有cuda用cuda，没有就用cpu\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 加载网络，图片单通道1，分类为1。\n",
    "    net = UNet(n_channels=1, n_classes=1)\n",
    "    # 将网络拷贝到deivce中\n",
    "    net.to(device=device)\n",
    "    # 指定训练集地址，开始训练\n",
    "    data_path = r\"E:\\opencv\\data\\train\"\n",
    "    train_net(net, device, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a15dd7",
   "metadata": {},
   "source": [
    "# 进行预测，目标保存在test文件夹里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b26ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:71: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "D:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:72: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    }
   ],
   "source": [
    "#进行预测\n",
    "if __name__ == \"__main__\":\n",
    "    # 选择设备，有cuda用cuda，没有就用cpu\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # 加载网络，图片单通道，分类为1。\n",
    "    net = UNet(n_channels=1, n_classes=1)\n",
    "    # 将网络拷贝到deivce中\n",
    "    net.to(device=device)\n",
    "    # 加载模型参数\n",
    "    net.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    # 测试模式\n",
    "    net.eval()\n",
    "    # 读取所有图片路径\n",
    "    tests_path = glob.glob(r'E:\\opencv\\data\\test\\*.png')\n",
    "    # 遍历所有图片\n",
    "    for test_path in tests_path:\n",
    "        # 保存结果地址\n",
    "        save_res_path = test_path.split('.')[0] + '_res.png'\n",
    "        # 读取图片\n",
    "        img = cv2.imread(test_path)\n",
    "        # 转为灰度图\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # 转为batch为1，通道为1，大小为512*512的数组\n",
    "        img = img.reshape(1, 1, img.shape[0], img.shape[1])\n",
    "        # 转为tensor\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        # 将tensor拷贝到device中，只用cpu就是拷贝到cpu中，用cuda就是拷贝到cuda中。\n",
    "        img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
    "        # 预测\n",
    "        pred = net(img_tensor)\n",
    "        # 提取结果\n",
    "        pred = np.array(pred.data.cpu()[0])[0]\n",
    "        # 处理结果\n",
    "        pred[pred >= 0.5] = 255\n",
    "        pred[pred < 0.5] = 0\n",
    "        # 保存图片\n",
    "        cv2.imwrite(save_res_path, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe2a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
